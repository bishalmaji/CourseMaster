{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwl/N5hkptKcphqJ48S/P8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bishalmaji/CourseMaster/blob/master/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7JNNKDpYbMJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as\n",
        "\n",
        "# Define the root directory.\n",
        "root_dir = '/content'  # This is the root directory in Google Colab.\n",
        "\n",
        "# Initialize lists to store extracted features and category labels.\n",
        "chroma_list = []\n",
        "spectral_centroid_list = []\n",
        "spectral_contrast_list = []\n",
        "mfcc_list = []\n",
        "zero_crossing_rate_list = []\n",
        "cry_category_list = []\n",
        "\n",
        "# Define a mapping from folder names to category labels.\n",
        "category_mapping = {\n",
        "    'hungry': 1,\n",
        "    'burping': 2,\n",
        "    'belly_pain': 3,\n",
        "    'discomfort': 4,\n",
        "    'tired': 5\n",
        "}\n",
        "\n",
        "# Iterate through each category folder.\n",
        "for category_name, category_label in category_mapping.items():\n",
        "    category_dir = os.path.join(root_dir, 'audios', category_name)\n",
        "\n",
        "    # Iterate through audio files in the category folder.\n",
        "    for audio_file in os.listdir(category_dir):\n",
        "        audio_path = os.path.join(category_dir, audio_file)\n",
        "\n",
        "        # Extract audio features, such as MFCC, chroma, spectral centroid, and spectral contrast.\n",
        "        audio_data, sample_rate = librosa.load(audio_path)\n",
        "        mfcc = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "        spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sample_rate)\n",
        "        spectral_contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sample_rate)\n",
        "\n",
        "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio_data)\n",
        "\n",
        "        # Append the extracted features and category label to their respective lists.\n",
        "        chroma_list.append(chroma)\n",
        "        spectral_centroid_list.append(spectral_centroid)\n",
        "        spectral_contrast_list.append(spectral_contrast)\n",
        "        mfcc_list.append(mfcc)\n",
        "        zero_crossing_rate_list.append(zero_crossing_rate)\n",
        "        cry_category_list.append(category_label)\n",
        "\n",
        "# Create a Pandas DataFrame with separate columns for each feature.\n",
        "data = pd.DataFrame({\n",
        "    'Chroma': chroma_list,\n",
        "    'SpectralCentroid': spectral_centroid_list,\n",
        "    'SpectralContrast': spectral_contrast_list,\n",
        "    'MFCC': mfcc_list,\n",
        "    'ZeroCrossingRate': zero_crossing_rate_list,\n",
        "    'CryCategory': cry_category_list\n",
        "})\n",
        "\n",
        "# Save the dataset to a CSV file.\n",
        "data.to_csv('/content/baby_cry_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten nested lists in the DataFrame\n",
        "data['Chroma'] = data['Chroma'].apply(lambda x: [item for sublist in x for item in sublist])\n",
        "data['SpectralCentroid'] = data['SpectralCentroid'].apply(lambda x: [item for sublist in x for item in sublist])\n",
        "data['SpectralContrast'] = data['SpectralContrast'].apply(lambda x: [item for sublist in x for item in sublist])\n",
        "data['MFCC'] = data['MFCC'].apply(lambda x: [item for sublist in x for item in sublist])\n",
        "data['ZeroCrossingRate'] = data['ZeroCrossingRate'].apply(lambda x: [item for sublist in x for item in sublist])\n",
        "\n",
        "# Save the dataset to a CSV file.\n",
        "data.to_csv('/content/baby_cry_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "qInmFBKBiAsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agegrating with scaled data**"
      ],
      "metadata": {
        "id": "Cx9gClwfMDb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaled_data=data.copy();\n",
        "\n",
        "# Apply the Min-Max scaling to the numeric columns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numeric_columns = scaled_data.select_dtypes(include=['int64', 'float64'])\n",
        "for column in numeric_columns.columns.difference(['CryCategory']):\n",
        "    scaled_data[column] = scaler.fit_transform(scaled_data[[column]])\n",
        "scaled_data.to_csv('/content/scaled_baby_cry_dataset.csv', index=False)\n",
        "\n",
        "# Now, add aggregation for the required features\n",
        "scaled_data['MFCC_Mean'] = scaled_data['MFCC'].apply(lambda x: np.mean(x))\n",
        "scaled_data['Chroma_Mean'] = scaled_data['Chroma'].apply(lambda x: np.mean(x))\n",
        "scaled_data['SpectralCentroid_Mean'] = scaled_data['SpectralCentroid'].apply(lambda x: np.mean(x))\n",
        "scaled_data['SpectralContrast_Mean'] = scaled_data['SpectralContrast'].apply(lambda x: np.mean(x))\n",
        "scaled_data['ZeroCrossingRate_Mean'] = scaled_data['ZeroCrossingRate'].apply(lambda x: np.mean(x))\n",
        "\n",
        "# Drop the original sequence columns\n",
        "scaled_data.drop(columns=['MFCC', 'Chroma', 'SpectralCentroid', 'SpectralContrast', 'ZeroCrossingRate'], inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "073VsBz3MCh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection**"
      ],
      "metadata": {
        "id": "tvrV8VKZQ3XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Split the data into features (X) and the target variable (y)\n",
        "X = scaled_data.drop(columns=['CryCategory'])\n",
        "y = scaled_data['CryCategory']\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to store feature importance\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort features by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# You can select the top N features based on their importance\n",
        "# For example, select the top 10 features\n",
        "selected_features = feature_importance_df.head(10)['Feature'].tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "ecG7atcfQ6ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0IZ43elRB-q",
        "outputId": "c1cba9da-ea42-413c-a3d6-53bf6f3c84fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SpectralCentroid_Mean', 'ZeroCrossingRate_Mean', 'MFCC_Mean', 'Chroma_Mean', 'SpectralContrast_Mean']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the model**\n",
        "\n",
        "---\n",
        "\n",
        "1.** Desicion Tree**"
      ],
      "metadata": {
        "id": "RLS5lCxwRe_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# Split the data into features (X) and the target (y)\n",
        "selected_f = ['SpectralContrast_Mean', 'SpectralCentroid_Mean','Chroma_Mean']\n",
        "X = scaled_data[selected_f]  # Use the selected features\n",
        "y = scaled_data['CryCategory']  # Your target variable\n",
        "\n",
        "# Split the data into a training set and a testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Decision Tree classifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "CIpBk9tuRaI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Random Forest **"
      ],
      "metadata": {
        "id": "J00KzHOwUZSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "selected_f = ['ZeroCrossingRate_Mean', 'SpectralCentroid_Mean','SpectralContrast_Mean']\n",
        "X = scaled_data[selected_f]  # Use the selected features\n",
        "y = scaled_data['CryCategory']  # Your target variable\n",
        "\n",
        "# Split the data into a training set and a testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "cuj-g8piUeH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. SVM**"
      ],
      "metadata": {
        "id": "jmEPbWUVJSbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "selected_f = ['SpectralCentroid_Mean']\n",
        "X = scaled_data[selected_features]  # Use the selected features\n",
        "y = scaled_data['CryCategory']  # Your target variable\n",
        "\n",
        "# Split the data into a training set and a testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_classifier = SVC(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Predicted class: {y_pred}')\n",
        "# Make predictions with the model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad1wF9k0f-AB",
        "outputId": "923314f4-96f6-49f3-b375-8cbb0736441c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80\n",
            "Predicted class: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVN0jnQKf7Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined model**"
      ],
      "metadata": {
        "id": "exLvQeH7XpBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create base models\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a voting classifier\n",
        "ensemble_model = VotingClassifier(estimators=[('dt', decision_tree), ('rf', random_forest)], voting='soft')\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oJFRNaAXovD",
        "outputId": "70086b64-6ad4-490f-e8d3-fe28dff29114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.71\n"
          ]
        }
      ]
    }
  ]
}